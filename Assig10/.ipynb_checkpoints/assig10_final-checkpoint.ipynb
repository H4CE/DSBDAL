{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "77b73d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus1=\"\"\"To Sherlock Holmes memory she is always the woman. I have seldom heard him mention her under any other name. In his eyes she eclipses and predominates the whole of her sex. It was not that he felt any emotion akin to love for Irene Adler. All emotions, and that one particularly, were abhorrent to his cold, precise but admirably balanced mind. He was, I take it, the most perfect reasoning and observing machine that the world has seen, but as a lover he would have placed himself in a false position. He never spoke of the softer passions, save with a gibe and a sneer. They were admirable things for the observer—excellent for drawing the veil from men’s motives and actions. But for the trained reasoner to admit such intrusions into his own delicate and finely adjusted temperament was to introduce a distracting factor which might throw a doubt upon all his mental results. Grit in a sensitive instrument, or a crack in one of his own high-power lenses, would not be more disturbing than a strong emotion in a nature such as his. And yet there was but one woman to him, and that woman was the late Irene Adler, of dubious and questionable memory.\"\"\"\n",
    "corpus2=\"\"\"I had seen little memory of Holmes lately. My marriage had drifted us away from each other. My own complete happiness, and the home-centred interests which rise up around the man who first finds himself master of his own establishment, were sufficient to absorb all my attention, while Holmes, who loathed every form of society with his whole Bohemian soul, remained in our lodgings in Baker Street, buried among his old books, and alternating from week to week between cocaine and ambition, the drowsiness of the drug, and the fierce energy of his own keen nature. He was still, as ever, deeply attracted by the study of crime, and occupied his immense faculties and extraordinary powers of observation in following out those clues, and clearing up those mysteries which had been abandoned as hopeless by the official police. From time to time I heard some vague account of his doings: of his summons to Odessa in the case of the Trepoff murder, of his clearing up of the singular tragedy of the Atkinson brothers at Trincomalee, and finally of the mission which he had accomplished so delicately and successfully for the reigning family of Holland. Beyond these signs of his activity, however, which I merely shared with all the readers of the daily press, I knew little of my former friend and companion.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "d2c80046",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "8ad7e6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "sentences1=sent_tokenize(corpus1)\n",
    "sentences2=sent_tokenize(corpus2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "376c9ff9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['To Sherlock Holmes memory she is always the woman.',\n",
       " 'I have seldom heard him mention her under any other name.',\n",
       " 'In his eyes she eclipses and predominates the whole of her sex.',\n",
       " 'It was not that he felt any emotion akin to love for Irene Adler.',\n",
       " 'All emotions, and that one particularly, were abhorrent to his cold, precise but admirably balanced mind.',\n",
       " 'He was, I take it, the most perfect reasoning and observing machine that the world has seen, but as a lover he would have placed himself in a false position.',\n",
       " 'He never spoke of the softer passions, save with a gibe and a sneer.',\n",
       " 'They were admirable things for the observer—excellent for drawing the veil from men’s motives and actions.',\n",
       " 'But for the trained reasoner to admit such intrusions into his own delicate and finely adjusted temperament was to introduce a distracting factor which might throw a doubt upon all his mental results.',\n",
       " 'Grit in a sensitive instrument, or a crack in one of his own high-power lenses, would not be more disturbing than a strong emotion in a nature such as his.',\n",
       " 'And yet there was but one woman to him, and that woman was the late Irene Adler, of dubious and questionable memory.']"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "24abe6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "word1=word_tokenize(corpus1)\n",
    "word2=word_tokenize(corpus2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "2c2a431d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['To',\n",
       " 'Sherlock',\n",
       " 'Holmes',\n",
       " 'memory',\n",
       " 'she',\n",
       " 'is',\n",
       " 'always',\n",
       " 'the',\n",
       " 'woman',\n",
       " '.',\n",
       " 'I',\n",
       " 'have',\n",
       " 'seldom',\n",
       " 'heard',\n",
       " 'him',\n",
       " 'mention',\n",
       " 'her',\n",
       " 'under',\n",
       " 'any',\n",
       " 'other',\n",
       " 'name',\n",
       " '.',\n",
       " 'In',\n",
       " 'his',\n",
       " 'eyes',\n",
       " 'she',\n",
       " 'eclipses',\n",
       " 'and',\n",
       " 'predominates',\n",
       " 'the',\n",
       " 'whole',\n",
       " 'of',\n",
       " 'her',\n",
       " 'sex',\n",
       " '.',\n",
       " 'It',\n",
       " 'was',\n",
       " 'not',\n",
       " 'that',\n",
       " 'he',\n",
       " 'felt',\n",
       " 'any',\n",
       " 'emotion',\n",
       " 'akin',\n",
       " 'to',\n",
       " 'love',\n",
       " 'for',\n",
       " 'Irene',\n",
       " 'Adler',\n",
       " '.',\n",
       " 'All',\n",
       " 'emotions',\n",
       " ',',\n",
       " 'and',\n",
       " 'that',\n",
       " 'one',\n",
       " 'particularly',\n",
       " ',',\n",
       " 'were',\n",
       " 'abhorrent',\n",
       " 'to',\n",
       " 'his',\n",
       " 'cold',\n",
       " ',',\n",
       " 'precise',\n",
       " 'but',\n",
       " 'admirably',\n",
       " 'balanced',\n",
       " 'mind',\n",
       " '.',\n",
       " 'He',\n",
       " 'was',\n",
       " ',',\n",
       " 'I',\n",
       " 'take',\n",
       " 'it',\n",
       " ',',\n",
       " 'the',\n",
       " 'most',\n",
       " 'perfect',\n",
       " 'reasoning',\n",
       " 'and',\n",
       " 'observing',\n",
       " 'machine',\n",
       " 'that',\n",
       " 'the',\n",
       " 'world',\n",
       " 'has',\n",
       " 'seen',\n",
       " ',',\n",
       " 'but',\n",
       " 'as',\n",
       " 'a',\n",
       " 'lover',\n",
       " 'he',\n",
       " 'would',\n",
       " 'have',\n",
       " 'placed',\n",
       " 'himself',\n",
       " 'in',\n",
       " 'a',\n",
       " 'false',\n",
       " 'position',\n",
       " '.',\n",
       " 'He',\n",
       " 'never',\n",
       " 'spoke',\n",
       " 'of',\n",
       " 'the',\n",
       " 'softer',\n",
       " 'passions',\n",
       " ',',\n",
       " 'save',\n",
       " 'with',\n",
       " 'a',\n",
       " 'gibe',\n",
       " 'and',\n",
       " 'a',\n",
       " 'sneer',\n",
       " '.',\n",
       " 'They',\n",
       " 'were',\n",
       " 'admirable',\n",
       " 'things',\n",
       " 'for',\n",
       " 'the',\n",
       " 'observer—excellent',\n",
       " 'for',\n",
       " 'drawing',\n",
       " 'the',\n",
       " 'veil',\n",
       " 'from',\n",
       " 'men',\n",
       " '’',\n",
       " 's',\n",
       " 'motives',\n",
       " 'and',\n",
       " 'actions',\n",
       " '.',\n",
       " 'But',\n",
       " 'for',\n",
       " 'the',\n",
       " 'trained',\n",
       " 'reasoner',\n",
       " 'to',\n",
       " 'admit',\n",
       " 'such',\n",
       " 'intrusions',\n",
       " 'into',\n",
       " 'his',\n",
       " 'own',\n",
       " 'delicate',\n",
       " 'and',\n",
       " 'finely',\n",
       " 'adjusted',\n",
       " 'temperament',\n",
       " 'was',\n",
       " 'to',\n",
       " 'introduce',\n",
       " 'a',\n",
       " 'distracting',\n",
       " 'factor',\n",
       " 'which',\n",
       " 'might',\n",
       " 'throw',\n",
       " 'a',\n",
       " 'doubt',\n",
       " 'upon',\n",
       " 'all',\n",
       " 'his',\n",
       " 'mental',\n",
       " 'results',\n",
       " '.',\n",
       " 'Grit',\n",
       " 'in',\n",
       " 'a',\n",
       " 'sensitive',\n",
       " 'instrument',\n",
       " ',',\n",
       " 'or',\n",
       " 'a',\n",
       " 'crack',\n",
       " 'in',\n",
       " 'one',\n",
       " 'of',\n",
       " 'his',\n",
       " 'own',\n",
       " 'high-power',\n",
       " 'lenses',\n",
       " ',',\n",
       " 'would',\n",
       " 'not',\n",
       " 'be',\n",
       " 'more',\n",
       " 'disturbing',\n",
       " 'than',\n",
       " 'a',\n",
       " 'strong',\n",
       " 'emotion',\n",
       " 'in',\n",
       " 'a',\n",
       " 'nature',\n",
       " 'such',\n",
       " 'as',\n",
       " 'his',\n",
       " '.',\n",
       " 'And',\n",
       " 'yet',\n",
       " 'there',\n",
       " 'was',\n",
       " 'but',\n",
       " 'one',\n",
       " 'woman',\n",
       " 'to',\n",
       " 'him',\n",
       " ',',\n",
       " 'and',\n",
       " 'that',\n",
       " 'woman',\n",
       " 'was',\n",
       " 'the',\n",
       " 'late',\n",
       " 'Irene',\n",
       " 'Adler',\n",
       " ',',\n",
       " 'of',\n",
       " 'dubious',\n",
       " 'and',\n",
       " 'questionable',\n",
       " 'memory',\n",
       " '.']"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "201752d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp=spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "ed8e676c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To --> adposition ( ADP )\n",
      "Sherlock --> proper noun ( PROPN )\n",
      "Holmes --> proper noun ( PROPN )\n",
      "memory --> noun ( NOUN )\n",
      "she --> pronoun ( PRON )\n",
      "is --> auxiliary ( AUX )\n",
      "always --> adverb ( ADV )\n",
      "the --> determiner ( DET )\n",
      "woman --> noun ( NOUN )\n",
      ". --> punctuation ( PUNCT )\n",
      "I --> pronoun ( PRON )\n",
      "have --> auxiliary ( AUX )\n",
      "seldom --> adverb ( ADV )\n",
      "heard --> verb ( VERB )\n",
      "him --> pronoun ( PRON )\n",
      "mention --> verb ( VERB )\n",
      "her --> pronoun ( PRON )\n",
      "under --> adposition ( ADP )\n",
      "any --> determiner ( DET )\n",
      "other --> adjective ( ADJ )\n",
      "name --> noun ( NOUN )\n",
      ". --> punctuation ( PUNCT )\n",
      "In --> adposition ( ADP )\n",
      "his --> pronoun ( PRON )\n",
      "eyes --> noun ( NOUN )\n",
      "she --> pronoun ( PRON )\n",
      "eclipses --> verb ( VERB )\n",
      "and --> coordinating conjunction ( CCONJ )\n",
      "predominates --> verb ( VERB )\n",
      "the --> determiner ( DET )\n",
      "whole --> noun ( NOUN )\n",
      "of --> adposition ( ADP )\n",
      "her --> pronoun ( PRON )\n",
      "sex --> noun ( NOUN )\n",
      ". --> punctuation ( PUNCT )\n",
      "It --> pronoun ( PRON )\n",
      "was --> auxiliary ( AUX )\n",
      "not --> particle ( PART )\n",
      "that --> subordinating conjunction ( SCONJ )\n",
      "he --> pronoun ( PRON )\n",
      "felt --> verb ( VERB )\n",
      "any --> determiner ( DET )\n",
      "emotion --> noun ( NOUN )\n",
      "akin --> adjective ( ADJ )\n",
      "to --> particle ( PART )\n",
      "love --> verb ( VERB )\n",
      "for --> adposition ( ADP )\n",
      "Irene --> proper noun ( PROPN )\n",
      "Adler --> proper noun ( PROPN )\n",
      ". --> punctuation ( PUNCT )\n",
      "All --> determiner ( DET )\n",
      "emotions --> noun ( NOUN )\n",
      ", --> punctuation ( PUNCT )\n",
      "and --> coordinating conjunction ( CCONJ )\n",
      "that --> determiner ( DET )\n",
      "one --> numeral ( NUM )\n",
      "particularly --> adverb ( ADV )\n",
      ", --> punctuation ( PUNCT )\n",
      "were --> auxiliary ( AUX )\n",
      "abhorrent --> adjective ( ADJ )\n",
      "to --> adposition ( ADP )\n",
      "his --> pronoun ( PRON )\n",
      "cold --> adjective ( ADJ )\n",
      ", --> punctuation ( PUNCT )\n",
      "precise --> adjective ( ADJ )\n",
      "but --> coordinating conjunction ( CCONJ )\n",
      "admirably --> adverb ( ADV )\n",
      "balanced --> adjective ( ADJ )\n",
      "mind --> noun ( NOUN )\n",
      ". --> punctuation ( PUNCT )\n",
      "He --> pronoun ( PRON )\n",
      "was --> auxiliary ( AUX )\n",
      ", --> punctuation ( PUNCT )\n",
      "I --> pronoun ( PRON )\n",
      "take --> verb ( VERB )\n",
      "it --> pronoun ( PRON )\n",
      ", --> punctuation ( PUNCT )\n",
      "the --> determiner ( DET )\n",
      "most --> adverb ( ADV )\n",
      "perfect --> adjective ( ADJ )\n",
      "reasoning --> noun ( NOUN )\n",
      "and --> coordinating conjunction ( CCONJ )\n",
      "observing --> verb ( VERB )\n",
      "machine --> noun ( NOUN )\n",
      "that --> pronoun ( PRON )\n",
      "the --> determiner ( DET )\n",
      "world --> noun ( NOUN )\n",
      "has --> auxiliary ( AUX )\n",
      "seen --> verb ( VERB )\n",
      ", --> punctuation ( PUNCT )\n",
      "but --> coordinating conjunction ( CCONJ )\n",
      "as --> adposition ( ADP )\n",
      "a --> determiner ( DET )\n",
      "lover --> noun ( NOUN )\n",
      "he --> pronoun ( PRON )\n",
      "would --> auxiliary ( AUX )\n",
      "have --> auxiliary ( AUX )\n",
      "placed --> verb ( VERB )\n",
      "himself --> pronoun ( PRON )\n",
      "in --> adposition ( ADP )\n",
      "a --> determiner ( DET )\n",
      "false --> adjective ( ADJ )\n",
      "position --> noun ( NOUN )\n",
      ". --> punctuation ( PUNCT )\n",
      "He --> pronoun ( PRON )\n",
      "never --> adverb ( ADV )\n",
      "spoke --> verb ( VERB )\n",
      "of --> adposition ( ADP )\n",
      "the --> determiner ( DET )\n",
      "softer --> adjective ( ADJ )\n",
      "passions --> noun ( NOUN )\n",
      ", --> punctuation ( PUNCT )\n",
      "save --> verb ( VERB )\n",
      "with --> adposition ( ADP )\n",
      "a --> determiner ( DET )\n",
      "gibe --> noun ( NOUN )\n",
      "and --> coordinating conjunction ( CCONJ )\n",
      "a --> determiner ( DET )\n",
      "sneer --> noun ( NOUN )\n",
      ". --> punctuation ( PUNCT )\n",
      "They --> pronoun ( PRON )\n",
      "were --> auxiliary ( AUX )\n",
      "admirable --> adjective ( ADJ )\n",
      "things --> noun ( NOUN )\n",
      "for --> adposition ( ADP )\n",
      "the --> determiner ( DET )\n",
      "observer --> noun ( NOUN )\n",
      "— --> punctuation ( PUNCT )\n",
      "excellent --> adjective ( ADJ )\n",
      "for --> adposition ( ADP )\n",
      "drawing --> verb ( VERB )\n",
      "the --> determiner ( DET )\n",
      "veil --> noun ( NOUN )\n",
      "from --> adposition ( ADP )\n",
      "men --> noun ( NOUN )\n",
      "’s --> particle ( PART )\n",
      "motives --> noun ( NOUN )\n",
      "and --> coordinating conjunction ( CCONJ )\n",
      "actions --> noun ( NOUN )\n",
      ". --> punctuation ( PUNCT )\n",
      "But --> coordinating conjunction ( CCONJ )\n",
      "for --> subordinating conjunction ( SCONJ )\n",
      "the --> determiner ( DET )\n",
      "trained --> verb ( VERB )\n",
      "reasoner --> noun ( NOUN )\n",
      "to --> particle ( PART )\n",
      "admit --> verb ( VERB )\n",
      "such --> adjective ( ADJ )\n",
      "intrusions --> noun ( NOUN )\n",
      "into --> adposition ( ADP )\n",
      "his --> pronoun ( PRON )\n",
      "own --> adjective ( ADJ )\n",
      "delicate --> adjective ( ADJ )\n",
      "and --> coordinating conjunction ( CCONJ )\n",
      "finely --> adverb ( ADV )\n",
      "adjusted --> verb ( VERB )\n",
      "temperament --> noun ( NOUN )\n",
      "was --> auxiliary ( AUX )\n",
      "to --> particle ( PART )\n",
      "introduce --> verb ( VERB )\n",
      "a --> determiner ( DET )\n",
      "distracting --> verb ( VERB )\n",
      "factor --> noun ( NOUN )\n",
      "which --> pronoun ( PRON )\n",
      "might --> auxiliary ( AUX )\n",
      "throw --> verb ( VERB )\n",
      "a --> determiner ( DET )\n",
      "doubt --> noun ( NOUN )\n",
      "upon --> subordinating conjunction ( SCONJ )\n",
      "all --> determiner ( DET )\n",
      "his --> pronoun ( PRON )\n",
      "mental --> adjective ( ADJ )\n",
      "results --> noun ( NOUN )\n",
      ". --> punctuation ( PUNCT )\n",
      "Grit --> noun ( NOUN )\n",
      "in --> adposition ( ADP )\n",
      "a --> determiner ( DET )\n",
      "sensitive --> adjective ( ADJ )\n",
      "instrument --> noun ( NOUN )\n",
      ", --> punctuation ( PUNCT )\n",
      "or --> coordinating conjunction ( CCONJ )\n",
      "a --> determiner ( DET )\n",
      "crack --> noun ( NOUN )\n",
      "in --> adposition ( ADP )\n",
      "one --> numeral ( NUM )\n",
      "of --> adposition ( ADP )\n",
      "his --> pronoun ( PRON )\n",
      "own --> adjective ( ADJ )\n",
      "high --> adjective ( ADJ )\n",
      "- --> punctuation ( PUNCT )\n",
      "power --> noun ( NOUN )\n",
      "lenses --> noun ( NOUN )\n",
      ", --> punctuation ( PUNCT )\n",
      "would --> auxiliary ( AUX )\n",
      "not --> particle ( PART )\n",
      "be --> auxiliary ( AUX )\n",
      "more --> adverb ( ADV )\n",
      "disturbing --> adjective ( ADJ )\n",
      "than --> adposition ( ADP )\n",
      "a --> determiner ( DET )\n",
      "strong --> adjective ( ADJ )\n",
      "emotion --> noun ( NOUN )\n",
      "in --> adposition ( ADP )\n",
      "a --> determiner ( DET )\n",
      "nature --> noun ( NOUN )\n",
      "such --> adjective ( ADJ )\n",
      "as --> adposition ( ADP )\n",
      "his --> pronoun ( PRON )\n",
      ". --> punctuation ( PUNCT )\n",
      "And --> coordinating conjunction ( CCONJ )\n",
      "yet --> adverb ( ADV )\n",
      "there --> pronoun ( PRON )\n",
      "was --> verb ( VERB )\n",
      "but --> coordinating conjunction ( CCONJ )\n",
      "one --> numeral ( NUM )\n",
      "woman --> noun ( NOUN )\n",
      "to --> adposition ( ADP )\n",
      "him --> pronoun ( PRON )\n",
      ", --> punctuation ( PUNCT )\n",
      "and --> coordinating conjunction ( CCONJ )\n",
      "that --> determiner ( DET )\n",
      "woman --> noun ( NOUN )\n",
      "was --> auxiliary ( AUX )\n",
      "the --> determiner ( DET )\n",
      "late --> adjective ( ADJ )\n",
      "Irene --> proper noun ( PROPN )\n",
      "Adler --> proper noun ( PROPN )\n",
      ", --> punctuation ( PUNCT )\n",
      "of --> adposition ( ADP )\n",
      "dubious --> adjective ( ADJ )\n",
      "and --> coordinating conjunction ( CCONJ )\n",
      "questionable --> adjective ( ADJ )\n",
      "memory --> noun ( NOUN )\n",
      ". --> punctuation ( PUNCT )\n"
     ]
    }
   ],
   "source": [
    "nlp_corpus1=nlp(corpus1)\n",
    "\n",
    "for token in nlp_corpus1:\n",
    "    print(token,\"-->\",spacy.explain(token.pos_),\"(\",token.pos_,\")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "2e489e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I --> pronoun ( PRON )\n",
      "had --> auxiliary ( AUX )\n",
      "seen --> verb ( VERB )\n",
      "little --> adjective ( ADJ )\n",
      "memory --> noun ( NOUN )\n",
      "of --> adposition ( ADP )\n",
      "Holmes --> proper noun ( PROPN )\n",
      "lately --> adverb ( ADV )\n",
      ". --> punctuation ( PUNCT )\n",
      "My --> pronoun ( PRON )\n",
      "marriage --> noun ( NOUN )\n",
      "had --> auxiliary ( AUX )\n",
      "drifted --> verb ( VERB )\n",
      "us --> pronoun ( PRON )\n",
      "away --> adverb ( ADV )\n",
      "from --> adposition ( ADP )\n",
      "each --> determiner ( DET )\n",
      "other --> adjective ( ADJ )\n",
      ". --> punctuation ( PUNCT )\n",
      "My --> pronoun ( PRON )\n",
      "own --> adjective ( ADJ )\n",
      "complete --> adjective ( ADJ )\n",
      "happiness --> noun ( NOUN )\n",
      ", --> punctuation ( PUNCT )\n",
      "and --> coordinating conjunction ( CCONJ )\n",
      "the --> determiner ( DET )\n",
      "home --> noun ( NOUN )\n",
      "- --> punctuation ( PUNCT )\n",
      "centred --> verb ( VERB )\n",
      "interests --> noun ( NOUN )\n",
      "which --> pronoun ( PRON )\n",
      "rise --> verb ( VERB )\n",
      "up --> adposition ( ADP )\n",
      "around --> adposition ( ADP )\n",
      "the --> determiner ( DET )\n",
      "man --> noun ( NOUN )\n",
      "who --> pronoun ( PRON )\n",
      "first --> adverb ( ADV )\n",
      "finds --> verb ( VERB )\n",
      "himself --> pronoun ( PRON )\n",
      "master --> noun ( NOUN )\n",
      "of --> adposition ( ADP )\n",
      "his --> pronoun ( PRON )\n",
      "own --> adjective ( ADJ )\n",
      "establishment --> noun ( NOUN )\n",
      ", --> punctuation ( PUNCT )\n",
      "were --> auxiliary ( AUX )\n",
      "sufficient --> adjective ( ADJ )\n",
      "to --> particle ( PART )\n",
      "absorb --> verb ( VERB )\n",
      "all --> determiner ( DET )\n",
      "my --> pronoun ( PRON )\n",
      "attention --> noun ( NOUN )\n",
      ", --> punctuation ( PUNCT )\n",
      "while --> subordinating conjunction ( SCONJ )\n",
      "Holmes --> proper noun ( PROPN )\n",
      ", --> punctuation ( PUNCT )\n",
      "who --> pronoun ( PRON )\n",
      "loathed --> verb ( VERB )\n",
      "every --> determiner ( DET )\n",
      "form --> noun ( NOUN )\n",
      "of --> adposition ( ADP )\n",
      "society --> noun ( NOUN )\n",
      "with --> adposition ( ADP )\n",
      "his --> pronoun ( PRON )\n",
      "whole --> adjective ( ADJ )\n",
      "Bohemian --> adjective ( ADJ )\n",
      "soul --> noun ( NOUN )\n",
      ", --> punctuation ( PUNCT )\n",
      "remained --> verb ( VERB )\n",
      "in --> adposition ( ADP )\n",
      "our --> pronoun ( PRON )\n",
      "lodgings --> noun ( NOUN )\n",
      "in --> adposition ( ADP )\n",
      "Baker --> proper noun ( PROPN )\n",
      "Street --> proper noun ( PROPN )\n",
      ", --> punctuation ( PUNCT )\n",
      "buried --> verb ( VERB )\n",
      "among --> adposition ( ADP )\n",
      "his --> pronoun ( PRON )\n",
      "old --> adjective ( ADJ )\n",
      "books --> noun ( NOUN )\n",
      ", --> punctuation ( PUNCT )\n",
      "and --> coordinating conjunction ( CCONJ )\n",
      "alternating --> verb ( VERB )\n",
      "from --> adposition ( ADP )\n",
      "week --> noun ( NOUN )\n",
      "to --> adposition ( ADP )\n",
      "week --> noun ( NOUN )\n",
      "between --> adposition ( ADP )\n",
      "cocaine --> noun ( NOUN )\n",
      "and --> coordinating conjunction ( CCONJ )\n",
      "ambition --> noun ( NOUN )\n",
      ", --> punctuation ( PUNCT )\n",
      "the --> determiner ( DET )\n",
      "drowsiness --> noun ( NOUN )\n",
      "of --> adposition ( ADP )\n",
      "the --> determiner ( DET )\n",
      "drug --> noun ( NOUN )\n",
      ", --> punctuation ( PUNCT )\n",
      "and --> coordinating conjunction ( CCONJ )\n",
      "the --> determiner ( DET )\n",
      "fierce --> adjective ( ADJ )\n",
      "energy --> noun ( NOUN )\n",
      "of --> adposition ( ADP )\n",
      "his --> pronoun ( PRON )\n",
      "own --> adjective ( ADJ )\n",
      "keen --> adjective ( ADJ )\n",
      "nature --> noun ( NOUN )\n",
      ". --> punctuation ( PUNCT )\n",
      "He --> pronoun ( PRON )\n",
      "was --> auxiliary ( AUX )\n",
      "still --> adverb ( ADV )\n",
      ", --> punctuation ( PUNCT )\n",
      "as --> adposition ( ADP )\n",
      "ever --> adverb ( ADV )\n",
      ", --> punctuation ( PUNCT )\n",
      "deeply --> adverb ( ADV )\n",
      "attracted --> verb ( VERB )\n",
      "by --> adposition ( ADP )\n",
      "the --> determiner ( DET )\n",
      "study --> noun ( NOUN )\n",
      "of --> adposition ( ADP )\n",
      "crime --> noun ( NOUN )\n",
      ", --> punctuation ( PUNCT )\n",
      "and --> coordinating conjunction ( CCONJ )\n",
      "occupied --> verb ( VERB )\n",
      "his --> pronoun ( PRON )\n",
      "immense --> adjective ( ADJ )\n",
      "faculties --> noun ( NOUN )\n",
      "and --> coordinating conjunction ( CCONJ )\n",
      "extraordinary --> adjective ( ADJ )\n",
      "powers --> noun ( NOUN )\n",
      "of --> adposition ( ADP )\n",
      "observation --> noun ( NOUN )\n",
      "in --> adposition ( ADP )\n",
      "following --> verb ( VERB )\n",
      "out --> adposition ( ADP )\n",
      "those --> determiner ( DET )\n",
      "clues --> noun ( NOUN )\n",
      ", --> punctuation ( PUNCT )\n",
      "and --> coordinating conjunction ( CCONJ )\n",
      "clearing --> verb ( VERB )\n",
      "up --> adposition ( ADP )\n",
      "those --> determiner ( DET )\n",
      "mysteries --> noun ( NOUN )\n",
      "which --> pronoun ( PRON )\n",
      "had --> auxiliary ( AUX )\n",
      "been --> auxiliary ( AUX )\n",
      "abandoned --> verb ( VERB )\n",
      "as --> adverb ( ADV )\n",
      "hopeless --> adjective ( ADJ )\n",
      "by --> adposition ( ADP )\n",
      "the --> determiner ( DET )\n",
      "official --> adjective ( ADJ )\n",
      "police --> noun ( NOUN )\n",
      ". --> punctuation ( PUNCT )\n",
      "From --> adposition ( ADP )\n",
      "time --> noun ( NOUN )\n",
      "to --> adposition ( ADP )\n",
      "time --> noun ( NOUN )\n",
      "I --> pronoun ( PRON )\n",
      "heard --> verb ( VERB )\n",
      "some --> determiner ( DET )\n",
      "vague --> adjective ( ADJ )\n",
      "account --> noun ( NOUN )\n",
      "of --> adposition ( ADP )\n",
      "his --> pronoun ( PRON )\n",
      "doings --> noun ( NOUN )\n",
      ": --> punctuation ( PUNCT )\n",
      "of --> adposition ( ADP )\n",
      "his --> pronoun ( PRON )\n",
      "summons --> noun ( NOUN )\n",
      "to --> adposition ( ADP )\n",
      "Odessa --> proper noun ( PROPN )\n",
      "in --> adposition ( ADP )\n",
      "the --> determiner ( DET )\n",
      "case --> noun ( NOUN )\n",
      "of --> adposition ( ADP )\n",
      "the --> determiner ( DET )\n",
      "Trepoff --> proper noun ( PROPN )\n",
      "murder --> noun ( NOUN )\n",
      ", --> punctuation ( PUNCT )\n",
      "of --> adposition ( ADP )\n",
      "his --> pronoun ( PRON )\n",
      "clearing --> noun ( NOUN )\n",
      "up --> adposition ( ADP )\n",
      "of --> adposition ( ADP )\n",
      "the --> determiner ( DET )\n",
      "singular --> adjective ( ADJ )\n",
      "tragedy --> noun ( NOUN )\n",
      "of --> adposition ( ADP )\n",
      "the --> determiner ( DET )\n",
      "Atkinson --> proper noun ( PROPN )\n",
      "brothers --> noun ( NOUN )\n",
      "at --> adposition ( ADP )\n",
      "Trincomalee --> proper noun ( PROPN )\n",
      ", --> punctuation ( PUNCT )\n",
      "and --> coordinating conjunction ( CCONJ )\n",
      "finally --> adverb ( ADV )\n",
      "of --> adposition ( ADP )\n",
      "the --> determiner ( DET )\n",
      "mission --> noun ( NOUN )\n",
      "which --> pronoun ( PRON )\n",
      "he --> pronoun ( PRON )\n",
      "had --> auxiliary ( AUX )\n",
      "accomplished --> verb ( VERB )\n",
      "so --> adverb ( ADV )\n",
      "delicately --> adverb ( ADV )\n",
      "and --> coordinating conjunction ( CCONJ )\n",
      "successfully --> adverb ( ADV )\n",
      "for --> adposition ( ADP )\n",
      "the --> determiner ( DET )\n",
      "reigning --> verb ( VERB )\n",
      "family --> noun ( NOUN )\n",
      "of --> adposition ( ADP )\n",
      "Holland --> proper noun ( PROPN )\n",
      ". --> punctuation ( PUNCT )\n",
      "Beyond --> adposition ( ADP )\n",
      "these --> determiner ( DET )\n",
      "signs --> noun ( NOUN )\n",
      "of --> adposition ( ADP )\n",
      "his --> pronoun ( PRON )\n",
      "activity --> noun ( NOUN )\n",
      ", --> punctuation ( PUNCT )\n",
      "however --> adverb ( ADV )\n",
      ", --> punctuation ( PUNCT )\n",
      "which --> pronoun ( PRON )\n",
      "I --> pronoun ( PRON )\n",
      "merely --> adverb ( ADV )\n",
      "shared --> verb ( VERB )\n",
      "with --> adposition ( ADP )\n",
      "all --> determiner ( DET )\n",
      "the --> determiner ( DET )\n",
      "readers --> noun ( NOUN )\n",
      "of --> adposition ( ADP )\n",
      "the --> determiner ( DET )\n",
      "daily --> adjective ( ADJ )\n",
      "press --> noun ( NOUN )\n",
      ", --> punctuation ( PUNCT )\n",
      "I --> pronoun ( PRON )\n",
      "knew --> verb ( VERB )\n",
      "little --> adjective ( ADJ )\n",
      "of --> adposition ( ADP )\n",
      "my --> pronoun ( PRON )\n",
      "former --> adjective ( ADJ )\n",
      "friend --> noun ( NOUN )\n",
      "and --> coordinating conjunction ( CCONJ )\n",
      "companion --> noun ( NOUN )\n",
      ". --> punctuation ( PUNCT )\n"
     ]
    }
   ],
   "source": [
    "nlp_corpus2=nlp(corpus2)\n",
    "\n",
    "for token in nlp_corpus2:\n",
    "    print(token,\"-->\",spacy.explain(token.pos_),\"(\",token.pos_,\")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "c37d192a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"'d\",\n",
       " \"'ll\",\n",
       " \"'m\",\n",
       " \"'re\",\n",
       " \"'s\",\n",
       " \"'ve\",\n",
       " 'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'across',\n",
       " 'after',\n",
       " 'afterwards',\n",
       " 'again',\n",
       " 'against',\n",
       " 'all',\n",
       " 'almost',\n",
       " 'alone',\n",
       " 'along',\n",
       " 'already',\n",
       " 'also',\n",
       " 'although',\n",
       " 'always',\n",
       " 'am',\n",
       " 'among',\n",
       " 'amongst',\n",
       " 'amount',\n",
       " 'an',\n",
       " 'and',\n",
       " 'another',\n",
       " 'any',\n",
       " 'anyhow',\n",
       " 'anyone',\n",
       " 'anything',\n",
       " 'anyway',\n",
       " 'anywhere',\n",
       " 'are',\n",
       " 'around',\n",
       " 'as',\n",
       " 'at',\n",
       " 'back',\n",
       " 'be',\n",
       " 'became',\n",
       " 'because',\n",
       " 'become',\n",
       " 'becomes',\n",
       " 'becoming',\n",
       " 'been',\n",
       " 'before',\n",
       " 'beforehand',\n",
       " 'behind',\n",
       " 'being',\n",
       " 'below',\n",
       " 'beside',\n",
       " 'besides',\n",
       " 'between',\n",
       " 'beyond',\n",
       " 'both',\n",
       " 'bottom',\n",
       " 'but',\n",
       " 'by',\n",
       " 'ca',\n",
       " 'call',\n",
       " 'can',\n",
       " 'cannot',\n",
       " 'could',\n",
       " 'did',\n",
       " 'do',\n",
       " 'does',\n",
       " 'doing',\n",
       " 'done',\n",
       " 'down',\n",
       " 'due',\n",
       " 'during',\n",
       " 'each',\n",
       " 'eight',\n",
       " 'either',\n",
       " 'eleven',\n",
       " 'else',\n",
       " 'elsewhere',\n",
       " 'empty',\n",
       " 'enough',\n",
       " 'even',\n",
       " 'ever',\n",
       " 'every',\n",
       " 'everyone',\n",
       " 'everything',\n",
       " 'everywhere',\n",
       " 'except',\n",
       " 'few',\n",
       " 'fifteen',\n",
       " 'fifty',\n",
       " 'first',\n",
       " 'five',\n",
       " 'for',\n",
       " 'former',\n",
       " 'formerly',\n",
       " 'forty',\n",
       " 'four',\n",
       " 'from',\n",
       " 'front',\n",
       " 'full',\n",
       " 'further',\n",
       " 'get',\n",
       " 'give',\n",
       " 'go',\n",
       " 'had',\n",
       " 'has',\n",
       " 'have',\n",
       " 'he',\n",
       " 'hence',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hereafter',\n",
       " 'hereby',\n",
       " 'herein',\n",
       " 'hereupon',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'however',\n",
       " 'hundred',\n",
       " 'i',\n",
       " 'if',\n",
       " 'in',\n",
       " 'indeed',\n",
       " 'into',\n",
       " 'is',\n",
       " 'it',\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'keep',\n",
       " 'last',\n",
       " 'latter',\n",
       " 'latterly',\n",
       " 'least',\n",
       " 'less',\n",
       " 'made',\n",
       " 'make',\n",
       " 'many',\n",
       " 'may',\n",
       " 'me',\n",
       " 'meanwhile',\n",
       " 'might',\n",
       " 'mine',\n",
       " 'more',\n",
       " 'moreover',\n",
       " 'most',\n",
       " 'mostly',\n",
       " 'move',\n",
       " 'much',\n",
       " 'must',\n",
       " 'my',\n",
       " 'myself',\n",
       " \"n't\",\n",
       " 'name',\n",
       " 'namely',\n",
       " 'neither',\n",
       " 'never',\n",
       " 'nevertheless',\n",
       " 'next',\n",
       " 'nine',\n",
       " 'no',\n",
       " 'nobody',\n",
       " 'none',\n",
       " 'noone',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'nothing',\n",
       " 'now',\n",
       " 'nowhere',\n",
       " 'n‘t',\n",
       " 'n’t',\n",
       " 'of',\n",
       " 'off',\n",
       " 'often',\n",
       " 'on',\n",
       " 'once',\n",
       " 'one',\n",
       " 'only',\n",
       " 'onto',\n",
       " 'or',\n",
       " 'other',\n",
       " 'others',\n",
       " 'otherwise',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 'part',\n",
       " 'per',\n",
       " 'perhaps',\n",
       " 'please',\n",
       " 'put',\n",
       " 'quite',\n",
       " 'rather',\n",
       " 're',\n",
       " 'really',\n",
       " 'regarding',\n",
       " 'same',\n",
       " 'say',\n",
       " 'see',\n",
       " 'seem',\n",
       " 'seemed',\n",
       " 'seeming',\n",
       " 'seems',\n",
       " 'serious',\n",
       " 'several',\n",
       " 'she',\n",
       " 'should',\n",
       " 'show',\n",
       " 'side',\n",
       " 'since',\n",
       " 'six',\n",
       " 'sixty',\n",
       " 'so',\n",
       " 'some',\n",
       " 'somehow',\n",
       " 'someone',\n",
       " 'something',\n",
       " 'sometime',\n",
       " 'sometimes',\n",
       " 'somewhere',\n",
       " 'still',\n",
       " 'such',\n",
       " 'take',\n",
       " 'ten',\n",
       " 'than',\n",
       " 'that',\n",
       " 'the',\n",
       " 'their',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'thence',\n",
       " 'there',\n",
       " 'thereafter',\n",
       " 'thereby',\n",
       " 'therefore',\n",
       " 'therein',\n",
       " 'thereupon',\n",
       " 'these',\n",
       " 'they',\n",
       " 'third',\n",
       " 'this',\n",
       " 'those',\n",
       " 'though',\n",
       " 'three',\n",
       " 'through',\n",
       " 'throughout',\n",
       " 'thru',\n",
       " 'thus',\n",
       " 'to',\n",
       " 'together',\n",
       " 'too',\n",
       " 'top',\n",
       " 'toward',\n",
       " 'towards',\n",
       " 'twelve',\n",
       " 'twenty',\n",
       " 'two',\n",
       " 'under',\n",
       " 'unless',\n",
       " 'until',\n",
       " 'up',\n",
       " 'upon',\n",
       " 'us',\n",
       " 'used',\n",
       " 'using',\n",
       " 'various',\n",
       " 'very',\n",
       " 'via',\n",
       " 'was',\n",
       " 'we',\n",
       " 'well',\n",
       " 'were',\n",
       " 'what',\n",
       " 'whatever',\n",
       " 'when',\n",
       " 'whence',\n",
       " 'whenever',\n",
       " 'where',\n",
       " 'whereafter',\n",
       " 'whereas',\n",
       " 'whereby',\n",
       " 'wherein',\n",
       " 'whereupon',\n",
       " 'wherever',\n",
       " 'whether',\n",
       " 'which',\n",
       " 'while',\n",
       " 'whither',\n",
       " 'who',\n",
       " 'whoever',\n",
       " 'whole',\n",
       " 'whom',\n",
       " 'whose',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'within',\n",
       " 'without',\n",
       " 'would',\n",
       " 'yet',\n",
       " 'you',\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " '‘d',\n",
       " '‘ll',\n",
       " '‘m',\n",
       " '‘re',\n",
       " '‘s',\n",
       " '‘ve',\n",
       " '’d',\n",
       " '’ll',\n",
       " '’m',\n",
       " '’re',\n",
       " '’s',\n",
       " '’ve'}"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stop words removal\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "09cbc761",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sherlock',\n",
       " 'Holmes',\n",
       " 'memory',\n",
       " 'woman',\n",
       " 'seldom',\n",
       " 'heard',\n",
       " 'mention',\n",
       " 'eyes',\n",
       " 'eclipses',\n",
       " 'predominates',\n",
       " 'sex',\n",
       " 'felt',\n",
       " 'emotion',\n",
       " 'akin',\n",
       " 'love',\n",
       " 'Irene',\n",
       " 'Adler',\n",
       " 'emotions',\n",
       " 'particularly',\n",
       " 'abhorrent',\n",
       " 'cold',\n",
       " 'precise',\n",
       " 'admirably',\n",
       " 'balanced',\n",
       " 'mind',\n",
       " 'perfect',\n",
       " 'reasoning',\n",
       " 'observing',\n",
       " 'machine',\n",
       " 'world',\n",
       " 'seen',\n",
       " 'lover',\n",
       " 'placed',\n",
       " 'false',\n",
       " 'position',\n",
       " 'spoke',\n",
       " 'softer',\n",
       " 'passions',\n",
       " 'save',\n",
       " 'gibe',\n",
       " 'sneer',\n",
       " 'admirable',\n",
       " 'things',\n",
       " 'observer',\n",
       " 'excellent',\n",
       " 'drawing',\n",
       " 'veil',\n",
       " 'men',\n",
       " 'motives',\n",
       " 'actions',\n",
       " 'trained',\n",
       " 'reasoner',\n",
       " 'admit',\n",
       " 'intrusions',\n",
       " 'delicate',\n",
       " 'finely',\n",
       " 'adjusted',\n",
       " 'temperament',\n",
       " 'introduce',\n",
       " 'distracting',\n",
       " 'factor',\n",
       " 'throw',\n",
       " 'doubt',\n",
       " 'mental',\n",
       " 'results',\n",
       " 'Grit',\n",
       " 'sensitive',\n",
       " 'instrument',\n",
       " 'crack',\n",
       " 'high',\n",
       " 'power',\n",
       " 'lenses',\n",
       " 'disturbing',\n",
       " 'strong',\n",
       " 'emotion',\n",
       " 'nature',\n",
       " 'woman',\n",
       " 'woman',\n",
       " 'late',\n",
       " 'Irene',\n",
       " 'Adler',\n",
       " 'dubious',\n",
       " 'questionable',\n",
       " 'memory']"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_corpus1=[]\n",
    "for word in nlp_corpus1:\n",
    "    if ((word.is_stop==False) and (word.is_punct==False)):\n",
    "    \tfiltered_corpus1.append(word.text) \n",
    "filtered_corpus1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "05f53c88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['seen',\n",
       " 'little',\n",
       " 'memory',\n",
       " 'Holmes',\n",
       " 'lately',\n",
       " 'marriage',\n",
       " 'drifted',\n",
       " 'away',\n",
       " 'complete',\n",
       " 'happiness',\n",
       " 'home',\n",
       " 'centred',\n",
       " 'interests',\n",
       " 'rise',\n",
       " 'man',\n",
       " 'finds',\n",
       " 'master',\n",
       " 'establishment',\n",
       " 'sufficient',\n",
       " 'absorb',\n",
       " 'attention',\n",
       " 'Holmes',\n",
       " 'loathed',\n",
       " 'form',\n",
       " 'society',\n",
       " 'Bohemian',\n",
       " 'soul',\n",
       " 'remained',\n",
       " 'lodgings',\n",
       " 'Baker',\n",
       " 'Street',\n",
       " 'buried',\n",
       " 'old',\n",
       " 'books',\n",
       " 'alternating',\n",
       " 'week',\n",
       " 'week',\n",
       " 'cocaine',\n",
       " 'ambition',\n",
       " 'drowsiness',\n",
       " 'drug',\n",
       " 'fierce',\n",
       " 'energy',\n",
       " 'keen',\n",
       " 'nature',\n",
       " 'deeply',\n",
       " 'attracted',\n",
       " 'study',\n",
       " 'crime',\n",
       " 'occupied',\n",
       " 'immense',\n",
       " 'faculties',\n",
       " 'extraordinary',\n",
       " 'powers',\n",
       " 'observation',\n",
       " 'following',\n",
       " 'clues',\n",
       " 'clearing',\n",
       " 'mysteries',\n",
       " 'abandoned',\n",
       " 'hopeless',\n",
       " 'official',\n",
       " 'police',\n",
       " 'time',\n",
       " 'time',\n",
       " 'heard',\n",
       " 'vague',\n",
       " 'account',\n",
       " 'doings',\n",
       " 'summons',\n",
       " 'Odessa',\n",
       " 'case',\n",
       " 'Trepoff',\n",
       " 'murder',\n",
       " 'clearing',\n",
       " 'singular',\n",
       " 'tragedy',\n",
       " 'Atkinson',\n",
       " 'brothers',\n",
       " 'Trincomalee',\n",
       " 'finally',\n",
       " 'mission',\n",
       " 'accomplished',\n",
       " 'delicately',\n",
       " 'successfully',\n",
       " 'reigning',\n",
       " 'family',\n",
       " 'Holland',\n",
       " 'signs',\n",
       " 'activity',\n",
       " 'merely',\n",
       " 'shared',\n",
       " 'readers',\n",
       " 'daily',\n",
       " 'press',\n",
       " 'knew',\n",
       " 'little',\n",
       " 'friend',\n",
       " 'companion']"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_corpus2=[]\n",
    "for word in nlp_corpus2:\n",
    "    if ((word.is_stop==False) and (word.is_punct==False)):\n",
    "    \tfiltered_corpus2.append(word.text) \n",
    "filtered_corpus2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "4d0c6535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sherlock --> sherlock\n",
      "Holmes --> holm\n",
      "memory --> memori\n",
      "woman --> woman\n",
      "seldom --> seldom\n",
      "heard --> heard\n",
      "mention --> mention\n",
      "eyes --> eye\n",
      "eclipses --> eclips\n",
      "predominates --> predomin\n",
      "sex --> sex\n",
      "felt --> felt\n",
      "emotion --> emot\n",
      "akin --> akin\n",
      "love --> love\n",
      "Irene --> iren\n",
      "Adler --> adler\n",
      "emotions --> emot\n",
      "particularly --> particularli\n",
      "abhorrent --> abhorr\n",
      "cold --> cold\n",
      "precise --> precis\n",
      "admirably --> admir\n",
      "balanced --> balanc\n",
      "mind --> mind\n",
      "perfect --> perfect\n",
      "reasoning --> reason\n",
      "observing --> observ\n",
      "machine --> machin\n",
      "world --> world\n",
      "seen --> seen\n",
      "lover --> lover\n",
      "placed --> place\n",
      "false --> fals\n",
      "position --> posit\n",
      "spoke --> spoke\n",
      "softer --> softer\n",
      "passions --> passion\n",
      "save --> save\n",
      "gibe --> gibe\n",
      "sneer --> sneer\n",
      "admirable --> admir\n",
      "things --> thing\n",
      "observer --> observ\n",
      "excellent --> excel\n",
      "drawing --> draw\n",
      "veil --> veil\n",
      "men --> men\n",
      "motives --> motiv\n",
      "actions --> action\n",
      "trained --> train\n",
      "reasoner --> reason\n",
      "admit --> admit\n",
      "intrusions --> intrus\n",
      "delicate --> delic\n",
      "finely --> fine\n",
      "adjusted --> adjust\n",
      "temperament --> tempera\n",
      "introduce --> introduc\n",
      "distracting --> distract\n",
      "factor --> factor\n",
      "throw --> throw\n",
      "doubt --> doubt\n",
      "mental --> mental\n",
      "results --> result\n",
      "Grit --> grit\n",
      "sensitive --> sensit\n",
      "instrument --> instrument\n",
      "crack --> crack\n",
      "high --> high\n",
      "power --> power\n",
      "lenses --> lens\n",
      "disturbing --> disturb\n",
      "strong --> strong\n",
      "emotion --> emot\n",
      "nature --> natur\n",
      "woman --> woman\n",
      "woman --> woman\n",
      "late --> late\n",
      "Irene --> iren\n",
      "Adler --> adler\n",
      "dubious --> dubiou\n",
      "questionable --> question\n",
      "memory --> memori\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "stemmer=PorterStemmer()\n",
    "for word in filtered_corpus1:\n",
    "    print(word,\"-->\",stemmer.stem(word))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "114d9152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seen --> seen\n",
      "little --> littl\n",
      "memory --> memori\n",
      "Holmes --> holm\n",
      "lately --> late\n",
      "marriage --> marriag\n",
      "drifted --> drift\n",
      "away --> away\n",
      "complete --> complet\n",
      "happiness --> happi\n",
      "home --> home\n",
      "centred --> centr\n",
      "interests --> interest\n",
      "rise --> rise\n",
      "man --> man\n",
      "finds --> find\n",
      "master --> master\n",
      "establishment --> establish\n",
      "sufficient --> suffici\n",
      "absorb --> absorb\n",
      "attention --> attent\n",
      "Holmes --> holm\n",
      "loathed --> loath\n",
      "form --> form\n",
      "society --> societi\n",
      "Bohemian --> bohemian\n",
      "soul --> soul\n",
      "remained --> remain\n",
      "lodgings --> lodg\n",
      "Baker --> baker\n",
      "Street --> street\n",
      "buried --> buri\n",
      "old --> old\n",
      "books --> book\n",
      "alternating --> altern\n",
      "week --> week\n",
      "week --> week\n",
      "cocaine --> cocain\n",
      "ambition --> ambit\n",
      "drowsiness --> drowsi\n",
      "drug --> drug\n",
      "fierce --> fierc\n",
      "energy --> energi\n",
      "keen --> keen\n",
      "nature --> natur\n",
      "deeply --> deepli\n",
      "attracted --> attract\n",
      "study --> studi\n",
      "crime --> crime\n",
      "occupied --> occupi\n",
      "immense --> immens\n",
      "faculties --> faculti\n",
      "extraordinary --> extraordinari\n",
      "powers --> power\n",
      "observation --> observ\n",
      "following --> follow\n",
      "clues --> clue\n",
      "clearing --> clear\n",
      "mysteries --> mysteri\n",
      "abandoned --> abandon\n",
      "hopeless --> hopeless\n",
      "official --> offici\n",
      "police --> polic\n",
      "time --> time\n",
      "time --> time\n",
      "heard --> heard\n",
      "vague --> vagu\n",
      "account --> account\n",
      "doings --> do\n",
      "summons --> summon\n",
      "Odessa --> odessa\n",
      "case --> case\n",
      "Trepoff --> trepoff\n",
      "murder --> murder\n",
      "clearing --> clear\n",
      "singular --> singular\n",
      "tragedy --> tragedi\n",
      "Atkinson --> atkinson\n",
      "brothers --> brother\n",
      "Trincomalee --> trincomale\n",
      "finally --> final\n",
      "mission --> mission\n",
      "accomplished --> accomplish\n",
      "delicately --> delic\n",
      "successfully --> success\n",
      "reigning --> reign\n",
      "family --> famili\n",
      "Holland --> holland\n",
      "signs --> sign\n",
      "activity --> activ\n",
      "merely --> mere\n",
      "shared --> share\n",
      "readers --> reader\n",
      "daily --> daili\n",
      "press --> press\n",
      "knew --> knew\n",
      "little --> littl\n",
      "friend --> friend\n",
      "companion --> companion\n"
     ]
    }
   ],
   "source": [
    "stemmer=PorterStemmer()\n",
    "for word in filtered_corpus2:\n",
    "    print(word,\"-->\",stemmer.stem(word.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "700fe670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sherlock --> Sherlock\n",
      "Holmes --> Holmes\n",
      "memory --> memory\n",
      "woman --> woman\n",
      "seldom --> seldom\n",
      "heard --> hear\n",
      "mention --> mention\n",
      "eyes --> eye\n",
      "eclipses --> eclipse\n",
      "predominates --> predominate\n",
      "sex --> sex\n",
      "felt --> feel\n",
      "emotion --> emotion\n",
      "akin --> akin\n",
      "love --> love\n",
      "Irene --> Irene\n",
      "Adler --> Adler\n",
      "emotions --> emotion\n",
      "particularly --> particularly\n",
      "abhorrent --> abhorrent\n",
      "cold --> cold\n",
      "precise --> precise\n",
      "admirably --> admirably\n",
      "balanced --> balanced\n",
      "mind --> mind\n",
      "perfect --> perfect\n",
      "reasoning --> reasoning\n",
      "observing --> observe\n",
      "machine --> machine\n",
      "world --> world\n",
      "seen --> see\n",
      "lover --> lover\n",
      "placed --> place\n",
      "false --> false\n",
      "position --> position\n",
      "spoke --> speak\n",
      "softer --> soft\n",
      "passions --> passion\n",
      "save --> save\n",
      "gibe --> gibe\n",
      "sneer --> sneer\n",
      "admirable --> admirable\n",
      "things --> thing\n",
      "observer --> observer\n",
      "excellent --> excellent\n",
      "drawing --> draw\n",
      "veil --> veil\n",
      "men --> man\n",
      "motives --> motive\n",
      "actions --> action\n",
      "trained --> train\n",
      "reasoner --> reasoner\n",
      "admit --> admit\n",
      "intrusions --> intrusion\n",
      "delicate --> delicate\n",
      "finely --> finely\n",
      "adjusted --> adjust\n",
      "temperament --> temperament\n",
      "introduce --> introduce\n",
      "distracting --> distract\n",
      "factor --> factor\n",
      "throw --> throw\n",
      "doubt --> doubt\n",
      "mental --> mental\n",
      "results --> result\n",
      "Grit --> grit\n",
      "sensitive --> sensitive\n",
      "instrument --> instrument\n",
      "crack --> crack\n",
      "high --> high\n",
      "power --> power\n",
      "lenses --> lense\n",
      "disturbing --> disturbing\n",
      "strong --> strong\n",
      "emotion --> emotion\n",
      "nature --> nature\n",
      "woman --> woman\n",
      "woman --> woman\n",
      "late --> late\n",
      "Irene --> Irene\n",
      "Adler --> Adler\n",
      "dubious --> dubious\n",
      "questionable --> questionable\n",
      "memory --> memory\n"
     ]
    }
   ],
   "source": [
    "#spacy madhe lemmatizer present aahe already so no need of importing a lemmatizer from nltk\n",
    "for word in filtered_corpus1:\n",
    "    print(word,\"-->\",word.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "42a379d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seen --> see\n",
      "little --> little\n",
      "memory --> memory\n",
      "Holmes --> Holmes\n",
      "lately --> lately\n",
      "marriage --> marriage\n",
      "drifted --> drift\n",
      "away --> away\n",
      "complete --> complete\n",
      "happiness --> happiness\n",
      "home --> home\n",
      "centred --> centre\n",
      "interests --> interest\n",
      "rise --> rise\n",
      "man --> man\n",
      "finds --> find\n",
      "master --> master\n",
      "establishment --> establishment\n",
      "sufficient --> sufficient\n",
      "absorb --> absorb\n",
      "attention --> attention\n",
      "Holmes --> Holmes\n",
      "loathed --> loathe\n",
      "form --> form\n",
      "society --> society\n",
      "Bohemian --> bohemian\n",
      "soul --> soul\n",
      "remained --> remain\n",
      "lodgings --> lodging\n",
      "Baker --> Baker\n",
      "Street --> Street\n",
      "buried --> bury\n",
      "old --> old\n",
      "books --> book\n",
      "alternating --> alternate\n",
      "week --> week\n",
      "week --> week\n",
      "cocaine --> cocaine\n",
      "ambition --> ambition\n",
      "drowsiness --> drowsiness\n",
      "drug --> drug\n",
      "fierce --> fierce\n",
      "energy --> energy\n",
      "keen --> keen\n",
      "nature --> nature\n",
      "deeply --> deeply\n",
      "attracted --> attract\n",
      "study --> study\n",
      "crime --> crime\n",
      "occupied --> occupy\n",
      "immense --> immense\n",
      "faculties --> faculty\n",
      "extraordinary --> extraordinary\n",
      "powers --> power\n",
      "observation --> observation\n",
      "following --> follow\n",
      "clues --> clue\n",
      "clearing --> clear\n",
      "mysteries --> mystery\n",
      "abandoned --> abandon\n",
      "hopeless --> hopeless\n",
      "official --> official\n",
      "police --> police\n",
      "time --> time\n",
      "time --> time\n",
      "heard --> hear\n",
      "vague --> vague\n",
      "account --> account\n",
      "doings --> doing\n",
      "summons --> summon\n",
      "Odessa --> Odessa\n",
      "case --> case\n",
      "Trepoff --> Trepoff\n",
      "murder --> murder\n",
      "clearing --> clearing\n",
      "singular --> singular\n",
      "tragedy --> tragedy\n",
      "Atkinson --> Atkinson\n",
      "brothers --> brother\n",
      "Trincomalee --> Trincomalee\n",
      "finally --> finally\n",
      "mission --> mission\n",
      "accomplished --> accomplish\n",
      "delicately --> delicately\n",
      "successfully --> successfully\n",
      "reigning --> reign\n",
      "family --> family\n",
      "Holland --> Holland\n",
      "signs --> sign\n",
      "activity --> activity\n",
      "merely --> merely\n",
      "shared --> share\n",
      "readers --> reader\n",
      "daily --> daily\n",
      "press --> press\n",
      "knew --> know\n",
      "little --> little\n",
      "friend --> friend\n",
      "companion --> companion\n"
     ]
    }
   ],
   "source": [
    "for word in filtered_corpus2:\n",
    "    print(word,\"-->\",word.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "a6f7bf68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sherlock --> 0.011904761904761904\n",
      "Holmes --> 0.011904761904761904\n",
      "memory --> 0.023809523809523808\n",
      "woman --> 0.03571428571428571\n",
      "seldom --> 0.011904761904761904\n",
      "heard --> 0.011904761904761904\n",
      "mention --> 0.011904761904761904\n",
      "eyes --> 0.011904761904761904\n",
      "eclipses --> 0.011904761904761904\n",
      "predominates --> 0.011904761904761904\n",
      "sex --> 0.011904761904761904\n",
      "felt --> 0.011904761904761904\n",
      "emotion --> 0.023809523809523808\n",
      "akin --> 0.011904761904761904\n",
      "love --> 0.011904761904761904\n",
      "Irene --> 0.023809523809523808\n",
      "Adler --> 0.023809523809523808\n",
      "emotions --> 0.011904761904761904\n",
      "particularly --> 0.011904761904761904\n",
      "abhorrent --> 0.011904761904761904\n",
      "cold --> 0.011904761904761904\n",
      "precise --> 0.011904761904761904\n",
      "admirably --> 0.011904761904761904\n",
      "balanced --> 0.011904761904761904\n",
      "mind --> 0.011904761904761904\n",
      "perfect --> 0.011904761904761904\n",
      "reasoning --> 0.011904761904761904\n",
      "observing --> 0.011904761904761904\n",
      "machine --> 0.011904761904761904\n",
      "world --> 0.011904761904761904\n",
      "seen --> 0.011904761904761904\n",
      "lover --> 0.011904761904761904\n",
      "placed --> 0.011904761904761904\n",
      "false --> 0.011904761904761904\n",
      "position --> 0.011904761904761904\n",
      "spoke --> 0.011904761904761904\n",
      "softer --> 0.011904761904761904\n",
      "passions --> 0.011904761904761904\n",
      "save --> 0.011904761904761904\n",
      "gibe --> 0.011904761904761904\n",
      "sneer --> 0.011904761904761904\n",
      "admirable --> 0.011904761904761904\n",
      "things --> 0.011904761904761904\n",
      "observer --> 0.011904761904761904\n",
      "excellent --> 0.011904761904761904\n",
      "drawing --> 0.011904761904761904\n",
      "veil --> 0.011904761904761904\n",
      "men --> 0.011904761904761904\n",
      "motives --> 0.011904761904761904\n",
      "actions --> 0.011904761904761904\n",
      "trained --> 0.011904761904761904\n",
      "reasoner --> 0.011904761904761904\n",
      "admit --> 0.011904761904761904\n",
      "intrusions --> 0.011904761904761904\n",
      "delicate --> 0.011904761904761904\n",
      "finely --> 0.011904761904761904\n",
      "adjusted --> 0.011904761904761904\n",
      "temperament --> 0.011904761904761904\n",
      "introduce --> 0.011904761904761904\n",
      "distracting --> 0.011904761904761904\n",
      "factor --> 0.011904761904761904\n",
      "throw --> 0.011904761904761904\n",
      "doubt --> 0.011904761904761904\n",
      "mental --> 0.011904761904761904\n",
      "results --> 0.011904761904761904\n",
      "Grit --> 0.011904761904761904\n",
      "sensitive --> 0.011904761904761904\n",
      "instrument --> 0.011904761904761904\n",
      "crack --> 0.011904761904761904\n",
      "high --> 0.011904761904761904\n",
      "power --> 0.011904761904761904\n",
      "lenses --> 0.011904761904761904\n",
      "disturbing --> 0.011904761904761904\n",
      "strong --> 0.011904761904761904\n",
      "nature --> 0.011904761904761904\n",
      "late --> 0.011904761904761904\n",
      "dubious --> 0.011904761904761904\n",
      "questionable --> 0.011904761904761904\n"
     ]
    }
   ],
   "source": [
    "#term frequncy\n",
    "tf1={}\n",
    "for word in filtered_corpus1:\n",
    "   tf1.update({word:(filtered_corpus1.count(word))/len(filtered_corpus1)}) \n",
    "\n",
    "for key,value in tf1.items():\n",
    "    print(key,\"-->\",value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "f5574746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seen --> 0.010101010101010102\n",
      "little --> 0.010101010101010102\n",
      "memory --> 0.010101010101010102\n",
      "Holmes --> 0.010101010101010102\n",
      "lately --> 0.010101010101010102\n",
      "marriage --> 0.010101010101010102\n",
      "drifted --> 0.010101010101010102\n",
      "away --> 0.010101010101010102\n",
      "complete --> 0.010101010101010102\n",
      "happiness --> 0.010101010101010102\n",
      "home --> 0.010101010101010102\n",
      "centred --> 0.010101010101010102\n",
      "interests --> 0.010101010101010102\n",
      "rise --> 0.010101010101010102\n",
      "man --> 0.010101010101010102\n",
      "finds --> 0.010101010101010102\n",
      "master --> 0.010101010101010102\n",
      "establishment --> 0.010101010101010102\n",
      "sufficient --> 0.010101010101010102\n",
      "absorb --> 0.010101010101010102\n",
      "attention --> 0.010101010101010102\n",
      "loathed --> 0.010101010101010102\n",
      "form --> 0.010101010101010102\n",
      "society --> 0.010101010101010102\n",
      "Bohemian --> 0.010101010101010102\n",
      "soul --> 0.010101010101010102\n",
      "remained --> 0.010101010101010102\n",
      "lodgings --> 0.010101010101010102\n",
      "Baker --> 0.010101010101010102\n",
      "Street --> 0.010101010101010102\n",
      "buried --> 0.010101010101010102\n",
      "old --> 0.010101010101010102\n",
      "books --> 0.010101010101010102\n",
      "alternating --> 0.010101010101010102\n",
      "week --> 0.010101010101010102\n",
      "cocaine --> 0.010101010101010102\n",
      "ambition --> 0.010101010101010102\n",
      "drowsiness --> 0.010101010101010102\n",
      "drug --> 0.010101010101010102\n",
      "fierce --> 0.010101010101010102\n",
      "energy --> 0.010101010101010102\n",
      "keen --> 0.010101010101010102\n",
      "nature --> 0.010101010101010102\n",
      "deeply --> 0.010101010101010102\n",
      "attracted --> 0.010101010101010102\n",
      "study --> 0.010101010101010102\n",
      "crime --> 0.010101010101010102\n",
      "occupied --> 0.010101010101010102\n",
      "immense --> 0.010101010101010102\n",
      "faculties --> 0.010101010101010102\n",
      "extraordinary --> 0.010101010101010102\n",
      "powers --> 0.010101010101010102\n",
      "observation --> 0.010101010101010102\n",
      "following --> 0.010101010101010102\n",
      "clues --> 0.010101010101010102\n",
      "clearing --> 0.010101010101010102\n",
      "mysteries --> 0.010101010101010102\n",
      "abandoned --> 0.010101010101010102\n",
      "hopeless --> 0.010101010101010102\n",
      "official --> 0.010101010101010102\n",
      "police --> 0.010101010101010102\n",
      "time --> 0.010101010101010102\n",
      "heard --> 0.010101010101010102\n",
      "vague --> 0.010101010101010102\n",
      "account --> 0.010101010101010102\n",
      "doings --> 0.010101010101010102\n",
      "summons --> 0.010101010101010102\n",
      "Odessa --> 0.010101010101010102\n",
      "case --> 0.010101010101010102\n",
      "Trepoff --> 0.010101010101010102\n",
      "murder --> 0.010101010101010102\n",
      "singular --> 0.010101010101010102\n",
      "tragedy --> 0.010101010101010102\n",
      "Atkinson --> 0.010101010101010102\n",
      "brothers --> 0.010101010101010102\n",
      "Trincomalee --> 0.010101010101010102\n",
      "finally --> 0.010101010101010102\n",
      "mission --> 0.010101010101010102\n",
      "accomplished --> 0.010101010101010102\n",
      "delicately --> 0.010101010101010102\n",
      "successfully --> 0.010101010101010102\n",
      "reigning --> 0.010101010101010102\n",
      "family --> 0.010101010101010102\n",
      "Holland --> 0.010101010101010102\n",
      "signs --> 0.010101010101010102\n",
      "activity --> 0.010101010101010102\n",
      "merely --> 0.010101010101010102\n",
      "shared --> 0.010101010101010102\n",
      "readers --> 0.010101010101010102\n",
      "daily --> 0.010101010101010102\n",
      "press --> 0.010101010101010102\n",
      "knew --> 0.010101010101010102\n",
      "friend --> 0.010101010101010102\n",
      "companion --> 0.010101010101010102\n"
     ]
    }
   ],
   "source": [
    "tf2={}\n",
    "for word in filtered_corpus2:\n",
    "   tf2.update({word.text:(filtered_corpus2.count(word))/len(filtered_corpus2)}) \n",
    "\n",
    "for key,value in tf2.items():\n",
    "    print(key,\"-->\",value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "ab45c174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IDF for 1: \n",
      "{'Sherlock': 0.6931471805599453, 'Holmes': 0.0, 'memory': 0.0, 'woman': 0.6931471805599453, 'seldom': 0.6931471805599453, 'heard': 0.0, 'mention': 0.6931471805599453, 'eyes': 0.6931471805599453, 'eclipses': 0.6931471805599453, 'predominates': 0.6931471805599453, 'sex': 0.6931471805599453, 'felt': 0.6931471805599453, 'emotion': 0.6931471805599453, 'akin': 0.6931471805599453, 'love': 0.6931471805599453, 'Irene': 0.6931471805599453, 'Adler': 0.6931471805599453, 'emotions': 0.6931471805599453, 'particularly': 0.6931471805599453, 'abhorrent': 0.6931471805599453, 'cold': 0.6931471805599453, 'precise': 0.6931471805599453, 'admirably': 0.6931471805599453, 'balanced': 0.6931471805599453, 'mind': 0.6931471805599453, 'perfect': 0.6931471805599453, 'reasoning': 0.6931471805599453, 'observing': 0.6931471805599453, 'machine': 0.6931471805599453, 'world': 0.6931471805599453, 'seen': 0.0, 'lover': 0.6931471805599453, 'placed': 0.6931471805599453, 'false': 0.6931471805599453, 'position': 0.6931471805599453, 'spoke': 0.6931471805599453, 'softer': 0.6931471805599453, 'passions': 0.6931471805599453, 'save': 0.6931471805599453, 'gibe': 0.6931471805599453, 'sneer': 0.6931471805599453, 'admirable': 0.6931471805599453, 'things': 0.6931471805599453, 'observer': 0.6931471805599453, 'excellent': 0.6931471805599453, 'drawing': 0.6931471805599453, 'veil': 0.6931471805599453, 'men': 0.6931471805599453, 'motives': 0.6931471805599453, 'actions': 0.6931471805599453, 'trained': 0.6931471805599453, 'reasoner': 0.6931471805599453, 'admit': 0.6931471805599453, 'intrusions': 0.6931471805599453, 'delicate': 0.6931471805599453, 'finely': 0.6931471805599453, 'adjusted': 0.6931471805599453, 'temperament': 0.6931471805599453, 'introduce': 0.6931471805599453, 'distracting': 0.6931471805599453, 'factor': 0.6931471805599453, 'throw': 0.6931471805599453, 'doubt': 0.6931471805599453, 'mental': 0.6931471805599453, 'results': 0.6931471805599453, 'Grit': 0.6931471805599453, 'sensitive': 0.6931471805599453, 'instrument': 0.6931471805599453, 'crack': 0.6931471805599453, 'high': 0.6931471805599453, 'power': 0.6931471805599453, 'lenses': 0.6931471805599453, 'disturbing': 0.6931471805599453, 'strong': 0.6931471805599453, 'nature': 0.0, 'late': 0.6931471805599453, 'dubious': 0.6931471805599453, 'questionable': 0.6931471805599453}\n",
      "\n",
      "\n",
      "IDF for 2: \n",
      "{'seen': 0.0, 'little': 0.6931471805599453, 'memory': 0.0, 'Holmes': 0.0, 'lately': 0.6931471805599453, 'marriage': 0.6931471805599453, 'drifted': 0.6931471805599453, 'away': 0.6931471805599453, 'complete': 0.6931471805599453, 'happiness': 0.6931471805599453, 'home': 0.6931471805599453, 'centred': 0.6931471805599453, 'interests': 0.6931471805599453, 'rise': 0.6931471805599453, 'man': 0.6931471805599453, 'finds': 0.6931471805599453, 'master': 0.6931471805599453, 'establishment': 0.6931471805599453, 'sufficient': 0.6931471805599453, 'absorb': 0.6931471805599453, 'attention': 0.6931471805599453, 'loathed': 0.6931471805599453, 'form': 0.6931471805599453, 'society': 0.6931471805599453, 'Bohemian': 0.6931471805599453, 'soul': 0.6931471805599453, 'remained': 0.6931471805599453, 'lodgings': 0.6931471805599453, 'Baker': 0.6931471805599453, 'Street': 0.6931471805599453, 'buried': 0.6931471805599453, 'old': 0.6931471805599453, 'books': 0.6931471805599453, 'alternating': 0.6931471805599453, 'week': 0.6931471805599453, 'cocaine': 0.6931471805599453, 'ambition': 0.6931471805599453, 'drowsiness': 0.6931471805599453, 'drug': 0.6931471805599453, 'fierce': 0.6931471805599453, 'energy': 0.6931471805599453, 'keen': 0.6931471805599453, 'nature': 0.0, 'deeply': 0.6931471805599453, 'attracted': 0.6931471805599453, 'study': 0.6931471805599453, 'crime': 0.6931471805599453, 'occupied': 0.6931471805599453, 'immense': 0.6931471805599453, 'faculties': 0.6931471805599453, 'extraordinary': 0.6931471805599453, 'powers': 0.6931471805599453, 'observation': 0.6931471805599453, 'following': 0.6931471805599453, 'clues': 0.6931471805599453, 'clearing': 0.6931471805599453, 'mysteries': 0.6931471805599453, 'abandoned': 0.6931471805599453, 'hopeless': 0.6931471805599453, 'official': 0.6931471805599453, 'police': 0.6931471805599453, 'time': 0.6931471805599453, 'heard': 0.0, 'vague': 0.6931471805599453, 'account': 0.6931471805599453, 'doings': 0.6931471805599453, 'summons': 0.6931471805599453, 'Odessa': 0.6931471805599453, 'case': 0.6931471805599453, 'Trepoff': 0.6931471805599453, 'murder': 0.6931471805599453, 'singular': 0.6931471805599453, 'tragedy': 0.6931471805599453, 'Atkinson': 0.6931471805599453, 'brothers': 0.6931471805599453, 'Trincomalee': 0.6931471805599453, 'finally': 0.6931471805599453, 'mission': 0.6931471805599453, 'accomplished': 0.6931471805599453, 'delicately': 0.6931471805599453, 'successfully': 0.6931471805599453, 'reigning': 0.6931471805599453, 'family': 0.6931471805599453, 'Holland': 0.6931471805599453, 'signs': 0.6931471805599453, 'activity': 0.6931471805599453, 'merely': 0.6931471805599453, 'shared': 0.6931471805599453, 'readers': 0.6931471805599453, 'daily': 0.6931471805599453, 'press': 0.6931471805599453, 'knew': 0.6931471805599453, 'friend': 0.6931471805599453, 'companion': 0.6931471805599453}\n"
     ]
    }
   ],
   "source": [
    "#idf of a word is the log( totalNum of Documents/number of documents in which the word appears)\n",
    "import math\n",
    "idf1 = {}\n",
    "\n",
    "for w in filtered_corpus1:\n",
    "  cnt = 1\n",
    "  if filtered_corpus2.count(w) > 0:\n",
    "    cnt += 1\n",
    "  \n",
    "  f = math.log(2/cnt)\n",
    "  idf1.update({w: f})\n",
    "\n",
    "print(\"IDF for 1: \")\n",
    "print(idf1)\n",
    "\n",
    "print()\n",
    "print()\n",
    "idf2 = {}\n",
    "\n",
    "for w in filtered_corpus2:\n",
    "  cnt = 1\n",
    "  if filtered_corpus1.count(w) > 0:\n",
    "    cnt += 1\n",
    "  \n",
    "  f = math.log(2/cnt)\n",
    "  idf2.update({w: f})\n",
    "\n",
    "print(\"IDF for 2: \")\n",
    "print(idf2)\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e098a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
